{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-project: Vocal Activity Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement a vocal activity detection (VAD) system in this mini-project. VAD aims at detection speech and nonspeech regions in a given utterance, and it is an important module in many speech commnunication applications:\n",
    "  - Assume that you are making a phone call, and your signal strength or network condition is bad. Typically, speech communication system encodes/compresses your voice into a compact representation, transmits it to the receiver, and deecodes/decompresses it back to your voice. Such transmission needs to be applied for both speech and non-speech regions. With VAD, the system does not need to transmit the non-speech or silent regions as they don't contain useful information. This can save the computation and network bandwidth.\n",
    "  \n",
    "A VAD module detects speech and non-speech regions through a classifier. The problem of VAD can be defined as a binary classification problem, where we assign a label \"yes\" or \"no\" to each short frame denoting whether it is a speech or non-speech frame. There are many ways that we can construct a classifier, and in this mini-project we will implement two methods: a support vector machine (SVM) classifier and a neural network classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start building the models, let's first prepare the dataset for VAD and do some simple visualization.\n",
    "\n",
    "The audio, adopted from https://github.com/jtkim-kaist/VAD, is a 15 minute clip recorded at a bus station by a cellphone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import time\n",
    "\n",
    "# load the audio file\n",
    "audio, sr = sf.read('park.wav')\n",
    "\n",
    "# visualize the audio\n",
    "plt.plot(audio)\n",
    "ticks_in_second = np.arange(len(audio)) / sr\n",
    "max_second = np.floor(ticks_in_second[-1])\n",
    "plt.xticks(ticks=np.arange(0, (max_second+1)*sr, (max_second+1)*sr/4), \n",
    "           labels=np.arange(0, (max_second+1), (max_second+1)/4))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can listen to part of it to get an intuition about what it sounds like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(audio[sr*15:sr*25], rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can here wind noise, street noise, and people speaking. The task of VAD is to detect the regions where the people speak.\n",
    "\n",
    "In this mini-project we will train and test our models in STFT domain. Let's calculate the **STFT magnitude spectrogram** and **Mel spectrogram** of this audio. \n",
    "\n",
    "Feel free to use librosa functions. Use **win_length=n_fft=512** and **hop_length=256** for STFT and Mel spectrogram, and **n_mels=64** for Mel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between win_length and hop_length? What happens if hop_length > win_length?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: enter your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate Magnitude Spectrogram\n",
    "\n",
    "audio_spec = None\n",
    "audio_spec_mag = None\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(audio_spec_mag[:,1500:2000]**0.33, origin='lower')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate Mel Spectrogram\n",
    "# use 64 filters for Mel filterbank\n",
    "\n",
    "mel_spec = None\n",
    "\n",
    "# visualize part of it\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.imshow(mel_spec[:,1500:2000]**0.33, origin='lower')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can load the frame-level labels for this audio clip. I've already processed the labels so that they match the length of the magnitude spectrogram above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the label\n",
    "label = np.asarray(np.load('audio_label.npy'))\n",
    "\n",
    "# visualize part of it\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(label[1000:6000])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize all of it\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(label)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the first 10000 frames for testing, 10000-20000 frames for validation, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = mel_spec[:,20000:]\n",
    "val_data = mel_spec[:,10000:20000]\n",
    "test_data = mel_spec[:,:10000]\n",
    "\n",
    "train_label = label[20000:]\n",
    "val_label = label[10000:20000]\n",
    "test_label = label[:10000]\n",
    "\n",
    "# MVN\n",
    "train_mean = np.mean(train_data, 1)\n",
    "train_var = np.var(train_data, 1)\n",
    "\n",
    "train_data = (train_data - train_mean[:,np.newaxis]) / train_var[:,np.newaxis]\n",
    "val_data = (val_data - train_mean[:,np.newaxis]) / train_var[:,np.newaxis]\n",
    "test_data = (test_data - train_mean[:,np.newaxis]) / train_var[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are done with data preparation. Note that here we directly load all the data into the memory as the size of the data is pretty small. For large-scale dataset, you may still need to save the processed data to harddisk and load them with the *DataLoader* method in the Neural Network Basics homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement accuracy calculation\n",
    "def Accuracy(predicts, labels):\n",
    "    '''\n",
    "    Compute accuracy of predicted labels against true labels.\n",
    "    args:\n",
    "        predicts: binary array or tensor of shape (num_frame, )\n",
    "        labels: binary array or tensor of shape (num_frame, )\n",
    "    return:\n",
    "        scalar float accuracy between 0 and 1\n",
    "    '''\n",
    "    \n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining whether a frame is speech or non-speech corresponds to a binary classification problem - we have two classes \"speech\" and \"non-speech\", and the model needs to make a prediction. \n",
    "\n",
    "Support vector machine (SVM) is a class of powerful classifiers before the dominance of neural networks, and is still one of the most important and widely-used tool nowadays. I will not go into the details of SVMs, and I just borrow a figure from [the Wikipedia page](https://en.wikipedia.org/wiki/Support_vector_machine) to show the intuition behind SVM:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/SVM_margin.png/494px-SVM_margin.png\">\n",
    "\n",
    "As you can see, a linear SVM attempts to find a \"line\" (\"hyperplane\" in a high-dimensional space) that separates the two classes of features. It is generally used as a linear classifier, as it assumes that the features from different classes are **linearly separable**. \n",
    "\n",
    "When you train a SVM classifier, you fit the training dataset as well as the corresponding label to the classifier to learn the parameters (i.e. model weights). During test time, you only feed the test dataset into the model and the model makes predictions about the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this mini-project we will not ask you to implement a SVM classifier from scratch. Instead you are asked to use the [*sklearn* library](https://scikit-learn.org/stable/modules/svm.html) and train a SVM classifier with the data we prepared above.\n",
    "\n",
    "We will use a linear SVM classifier, denoted by [*LinearSVC*](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) in th sklearn library, for this section. Click the link for *LinearSVC* for its usage, take a look at the examples provided, and apply it on our VAD data. You do not need to change any default parameters.\n",
    "\n",
    "Don't worry about *ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# TODO: use the LinearSVC class for the VAD data\n",
    "# Set random_state to 0 and max_iter to 1e3 for a fair comparison\n",
    "\n",
    "# Instantiate a SVM classifier\n",
    "svm = None\n",
    "\n",
    "# Train your classifier \n",
    "\n",
    "\n",
    "# Make prediction on the training, validation, and test sets\n",
    "train_predict_svm = None\n",
    "val_predict_svm = None\n",
    "test_predict_svm = None\n",
    "\n",
    "# Calculate accuracy on the training, validation, and test sets\n",
    "train_acc_svm = None\n",
    "val_acc_svm = None\n",
    "test_acc_svm = None\n",
    "\n",
    "print(f'Train set accuracy: {str(round(train_acc_svm*100, 1))}%')\n",
    "print(f'Val set accuracy: {str(round(val_acc_svm*100, 1))}%')\n",
    "print(f'Test set accuracy: {str(round(test_acc_svm*100, 1))}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVM requires that the features are linearly separable. However, this is hardly the case for most of the tasks. No worries - for features that are not linearly separable, we can try to find a transformed representation of the features so that the transformed features are linearly separable in another feature space. In SVM, this is called the **kernel trick**, where the kernel can be a nonlinear mapping applied to the features that transforms them to another representation space. This gives us a nonlinear SVM classifier. We will not go into the details of the kernel tricks in SVM in this mini-project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, visualize the predictions from the Linear-SVM and compare with the target labels. What do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: visualize the predictions by Linear-SV and compare with target label\n",
    "# for train, val, and test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build a simple neural network classifier. We wil use the 3-layer MLP in the Neural Network Basics homework for the classifier. The MLP we discussed in the previous homework is for the task of autoencoding, but here we need to perform a biinary classification task. As a result, we need to change both the input and output dimensions of the model.\n",
    "\n",
    "The input dimension here is the dimension of the MFCC features (remember that MLP processes each frame independently). Since we are doing a binary classification, the output dimension can thus be 1, representing the **probability** that the input frame belongs to speech or non-speech region. We use *Sigmoid function* to ensure that the range of the output meets the requirement of a probability measure, i.e. between 0 and 1.\n",
    "\n",
    "Implement the MLP below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# TODO: adopt the 3-layer MLP from the Neural Network Basics homework here\n",
    "# Remember to modify the input/output dimensions\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the autoencoding task we used the mean-square error (MSE) as the training objective. For classification tasks, we typically use **cross-entropy (CE)** as the training objective. CE denotes how close two distributions are, and it is always nonnegative - lower values of CE means higher similarities of the two distributions. In our case where the target is either 0 or 1, i.e. the binary classification task, the loss is called the [**binary cross-entropy (BCE)** loss](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a):\n",
    "<img src=\"https://miro.medium.com/max/1096/1*rdBw0E-My8Gu3f_BOB6GMA.png\">\n",
    "\n",
    "Here **y** is the label (0 or 1), **p(y)** is the predicted probability (between 0 and 1), and **N** is the total number of training samples you have in a batch. The closer **p(y)** is to **y**, the lower value the loss function will get.\n",
    "\n",
    "Implement the BCE function in Pytorch. Note that Pytorch does have a built-in function for BCE, but you should not use it directly here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement BCE function\n",
    "\n",
    "def BCE(probs, labels, eps=1e-9):\n",
    "    \"\"\"\n",
    "    BCE between the predicted probabilities and the true labels.\n",
    "    args:\n",
    "        probs: shape (num_frame,), torch tensor\n",
    "        labels: shape (num_frame,), torch tensor\n",
    "        eps: a small value, what is this for?\n",
    "    return:\n",
    "        scalar float binary cross entropy averaged over the batch\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that during the training phase of the MLP, we evaluate the model performance on the validation set to select the best model. However, knowing the value of BCE does not mean that we know the actual classification accuracy. Thus we also need another function to calculate the accuracy given the predicted probabilities.\n",
    "\n",
    "Typically we use a simple threshold-based rule to determine the predicted label from the predicted probability: if the predicted probabiliti is higher than 0.5, then we categorize it into label 1, otherwise we categorize it to label 0. We can then compare the predicted label with the target label to calculate the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the MLP model with the training pipeline we used in the previous homework. Use BCE function for training, and Accuracy for validation to select the best model. \n",
    "\n",
    "Also note that the accuracy should be calculated on the entire validation set (10000 frames), so you should feed all the 10000 frames into the Accuracy function to get the correct value. You need to achieve over **85% accuracy on validation set** to get the full marks here, so play with the configurations of the MLP - nonlinearity in the hidden layers, number of hidden units, number of layers, learning rate, or any other tricks you know. Try to hit the highest accuracy you can achieve!\n",
    "\n",
    "You may also encounter NaNs during training. Think about why and how you can avoid it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "# TODO: Create DataLoader for all 3 dataset partitions. \n",
    "# But first, you need to create Dataset objects.\n",
    "# You can either save and load all the data via h5py, \n",
    "# or directly cast numpy arrays to TensorDataset.\n",
    "\n",
    "# Reference: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "batch_size = 32 # Pass it to DataLoader. Feel free to change it.\n",
    "train_dataset = None\n",
    "val_dataset = None\n",
    "test_dataset = None\n",
    "train_loader = None\n",
    "val_loader = None\n",
    "test_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: functions for training and validation\n",
    "# Use BCE during training, and Accuracy during validation\n",
    "\n",
    "def train(model, loader, opt, loss_fn):\n",
    "    '''\n",
    "    Training Step, called once per epoch.\n",
    "    Model is updated.\n",
    "    args:\n",
    "        model: nn.Module\n",
    "        loader: torch DataLoader\n",
    "        opt: torch.optim\n",
    "        loss_fn: differentiable loss_fn(probs, labels) -> scalar\n",
    "    return:\n",
    "        average training loss for this epoch\n",
    "    '''\n",
    "    model.train()\n",
    "    train_loss_batch = []\n",
    "    for data, labels in loader:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    train_loss_epoch = sum(train_loss_batch) / len(train_loss_batch)\n",
    "    \n",
    "    return float(train_loss_epoch)\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, return_results=False):\n",
    "    '''\n",
    "    Validation Step, called once per epoch.\n",
    "    args:\n",
    "        model: nn.Module\n",
    "        loader: torch DataLoader\n",
    "        criterion: criterion(predicts, labels) -> scalar\n",
    "    return:\n",
    "        average accuracy of all frames, and if return_results,\n",
    "        (predicted probabalities, predicted labels)\n",
    "    \n",
    "    '''\n",
    "    model.eval()\n",
    "    # probs is probability between 0 and 1;\n",
    "    # predicts is prediced label of 0 or 1.\n",
    "    all_labels, all_probs, all_predicts \\\n",
    "        = torch.zeros(0), torch.zeros(0), torch.zeros(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in loader:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "            all_labels = torch.cat([all_labels, labels])\n",
    "            all_probs = torch.cat([all_probs, probs])\n",
    "            all_predicts = torch.cat([all_predicts, predicts])    \n",
    "            \n",
    "    val_acc_epoch = None\n",
    "    \n",
    "    if return_results:\n",
    "        return float(val_acc_epoch), (all_probs, all_predicts)\n",
    "    else:\n",
    "        return float(val_acc_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: instantiate your model\n",
    "mlp = None\n",
    "    \n",
    "# TODO: initialize the optimizer here\n",
    "# you can still use Adam as the optimizer\n",
    "opt = None\n",
    "\n",
    "# hyperparameters\n",
    "\n",
    "total_epoch = None  # train the model for ? epochs\n",
    "model_save = 'best_MLP_VAD.pt'  # path to save the best validation model\n",
    "\n",
    "# main function\n",
    "\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "\n",
    "for epoch in range(1, total_epoch + 1):\n",
    "    train_loss_epoch = None\n",
    "    val_acc_epoch = None\n",
    "    \n",
    "    train_loss.append(train_loss_epoch)\n",
    "    val_acc.append(val_acc_epoch)\n",
    "    \n",
    "    print(f'Epoch No.{epoch}:')\n",
    "    print(f'      Training loss: {str(round(train_loss_epoch, 2))}')\n",
    "    print(f'      Validation accuracy: {str(round(val_acc_epoch*100, 1))}%')\n",
    "    \n",
    "    if train_loss[-1] == np.min(train_loss):\n",
    "        print('      Best training model found.')\n",
    "    if val_acc[-1] == np.max(val_acc):\n",
    "        # save current best model on validation set\n",
    "        with open(model_save, 'wb') as f:\n",
    "            torch.save(mlp.state_dict(), f)\n",
    "            print('      Best validation model found and saved.')\n",
    "    \n",
    "    print('-' * 99)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluate the best model found on the validation set on the training, validation and test sets\n",
    "# Remember to load the best validation model above before making the evaluation\n",
    "\n",
    "\n",
    "# TODO: print the accuracy on the three datasets\n",
    "final_train_acc = None\n",
    "final_val_acc = None\n",
    "final_test_acc, (test_prob_mlp, test_predict_mlp) = None, None\n",
    "\n",
    "# val acc should be above 0.85\n",
    "print(f'Final train acc {str(round(final_train_acc, 2))} | val acc {str(round(final_val_acc, 2))} | test acc {str(round(final_test_acc, 2))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the model with accuracy; Why cann't we also train the model with accuracy instead of binary cross entropy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: enter your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the difference between the accuracy on validation set and test set? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: enter your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do some visualization on the predictions. What can you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: visualize the output from the MLP on the test set (both probability and predicted label) and compare with the target label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a linear-SVM classifier and nonlinear MLP classifier. What are the pros and cons of them? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: enter your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we are directly using the model predictions as the predicted labels for speech and non-speech regions. There are many ways that we can improve the results, and here we will try one of the post-processing methods - **smoothing**.\n",
    "\n",
    "Smoothing is based on a straightforward intuition: if a frame is non-speech, then it is highly probably that its neighbouring frames are also non-speech. We can thus apply a local smoothing on the model predictions via moving average - the smoothed output at each frame is the average prediction output of its neighbouring frames.\n",
    "\n",
    "Let's implement the smoothing strategy for both Linear-SVM outputs and MLP outputs. Here let's set the number of neighbouring frames to 7: 3 in the past, 1 at the current frame, and 3 in the future. For the first 3 and last 3 frames where the number of past or future frames are not enough, we keep them unchanged.\n",
    "\n",
    "***Hint***: We can implement smoothing as a 1D convolution. The convolution kernel has length of 7, and is centered so that it sees 3 samples before and 3 samples after. Then, what should be the weights of this kernel?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement smoothing\n",
    "def smoothing(prediction, context=7):\n",
    "    # prediction: shape (num_frame,)\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: smoothing for Linear-SVM output label, print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: smoothing for MLP output probability, print the accuracy\n",
    "# The predicted labels are calculated after smoothing on the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: smoothing for MLP output label, print the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the MLP probabilities after smoothing, compare with the original probabilities. What do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: visualization of predicted labels after smoothing the MLP output probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: enter your discussions here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion: Evaluation Metrics for VAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only used the classification accuracy as the evaluation metric for the systems above. However, there are well-defined evaluation metris for VAD task. The evaluation metrics for VAD systems is typically done by the following 4 metrics [(Beritelli, F., et al., 2002)](https://ieeexplore.ieee.org/abstract/document/995824/):\n",
    "  -  **Front End Clipping (FEC)**: Clipping introduced in passing from noise to speech activity.\n",
    "  -  **Mid Speech Clipping (MSC)**: Clipping due to speech misclassified as noise.\n",
    "  -  **OVER**: Noise interpreted as speech due to the VAD flag remaining active in passing from speech activity to noise.\n",
    "  -  **Noise Detected as Speech (NDS)**: Noise interpreted as\n",
    "speech within a silence period.\n",
    "\n",
    "The metrics can be visualized as follows. The image is adopted from https://github.com/jtkim-kaist/VAD.\n",
    "<img src=\"https://user-images.githubusercontent.com/24668469/49742392-cd778680-fcdb-11e8-96b9-a599a4f85f4f.PNG\">\n",
    "\n",
    "If you are interested, you can try to implement the four metrics and evaluate the three models above with them. This is not part of the required excercises in this mini-project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion: Input to the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only used frame-level feature in the two models we built above. However, temporal information can be very important in audio processing tasks. There are several ways you can utilize the temporal information:\n",
    "  -  Use **context of features**: instead of using the feature of the current frame, concatenate the features in the neighbouring frames to the current frame to create a **context**.\n",
    "  -  Use **recurrent neural networks**: similar to the example we have in the Neural Network Basics homework.\n",
    "  \n",
    "You can play with different types of input features and compare the performance. This is not part of the required excercises in this mini-project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
